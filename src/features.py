#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
features.py â€” ëˆ„ì¶œ ì—†ì´ cross-horizon ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± + ì œí’ˆ íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§

ê¸°ëŠ¥ ê°œìš”
- ì•ˆì „í•œ DateTime ë³€í™˜(ì—´ ì¦ê°€ ì—†ì´, ê²°ì¸¡ ìµœì†Œí™”)
- ì™„ì „ ì¤‘ë³µí–‰ ì œê±°
- (Product_Number, DateTime) í‚¤ ì¤‘ë³µí–‰ í‰ê·  ì§‘ê³„(ìˆ˜ì¹˜í˜• mean, ë²”ì£¼í˜• first)
- cross-horizon íŒŒìƒ: lag_diff_T+1~T+4, lag_ratio_T+1~T+4, cumsum_lag, trend_sign,
  mean_future, std_future, instability_coef, growth_index_T4
- ì‹œê°„ íŒŒìƒ: Datetime ê¸°ë°˜ ìš”ì¼Â·ì›”Â·ì‹œÂ·ë¶„ ë° ì£¼ê¸°ì  ì¸ì½”ë”©(sin/cos)
- ì œí’ˆ íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§(K=4, ì €/ì¤‘/ê³ /ì¤‘ìš” ìˆ˜ìš”ë¡œ ì¬ë¼ë²¨)

CLI ì‚¬ìš©
python ./src/features.py --in ./data/data.csv --out ./data/feat.csv
"""

from __future__ import annotations
import argparse
import sys
import warnings
from typing import List, Optional, Tuple
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings("ignore", category=UserWarning)

# =========================
# ìœ í‹¸ í•¨ìˆ˜
# =========================

def _safe_parse_datetime(series: pd.Series) -> pd.Series:
    s_raw = series.astype(str).str.strip()
    parsed = pd.to_datetime(s_raw, format="%Y-%m-%d %H:%M:%S", errors="coerce")
    mask = parsed.isna() & s_raw.notna()
    if mask.any():
        parsed.loc[mask] = pd.to_datetime(s_raw.loc[mask], errors="coerce")
    mask = parsed.isna() & s_raw.notna()
    if mask.any():
        s_norm = (
            s_raw.loc[mask]
            .str.replace(".", "-", regex=False)
            .str.replace("/", "-", regex=False)
        )
        parsed.loc[mask] = pd.to_datetime(s_norm, errors="coerce")
    return parsed


def _drop_full_duplicates(df: pd.DataFrame) -> Tuple[pd.DataFrame, int]:
    before = len(df)
    df2 = df.drop_duplicates(keep="first").copy()
    removed = before - len(df2)
    if removed:
        print(f"ì™„ì „ ì¤‘ë³µ í–‰ ì œê±°: {removed}í–‰")
    return df2, removed


def _dedup_by_key_mean(df: pd.DataFrame, prod_col: str, dt_col: str) -> Tuple[pd.DataFrame, int]:
    before = len(df)
    if not {prod_col, dt_col}.issubset(df.columns):
        print("í‚¤ ì¤‘ë³µ ë³‘í•© ìƒëµ: í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df, 0

    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    num_cols = [c for c in num_cols if c not in [prod_col, dt_col]]
    non_num_cols = [c for c in df.columns if c not in num_cols + [prod_col, dt_col]]

    agg_dict = {**{c: "mean" for c in num_cols}, **{c: "first" for c in non_num_cols}}
    df2 = (
        df.groupby([prod_col, dt_col], as_index=False)
          .agg(agg_dict)
          .sort_values([prod_col, dt_col])
          .reset_index(drop=True)
    )
    removed = before - len(df2)
    if removed:
        print(f"({prod_col}, {dt_col}) ê¸°ì¤€ ë³‘í•©: {removed}í–‰ ì¶•ì†Œ")
    return df2, removed


def _stabilize_ratio(s: pd.Series, clip_min: float = 0.0, clip_max: float = 5.0, fill_when_nan: float = 0.0) -> pd.Series:
    s = s.replace([np.inf, -np.inf], np.nan).fillna(fill_when_nan)
    if clip_min is not None or clip_max is not None:
        s = np.clip(s, clip_min if clip_min is not None else s.min(),
                    clip_max if clip_max is not None else s.max())
    return s

# =========================
# íŒŒìƒë³€ìˆ˜ ìƒì„±
# =========================

COLS = {
    "prod": "Product_Number",
    "dt": "DateTime",
    "demand_T": "Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
    "demand_Tp1": "T+1ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
    "demand_Tp2": "T+2ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
    "demand_Tp3": "T+3ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
    "demand_Tp4": "T+4ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
}

def add_cross_horizon_features(df: pd.DataFrame) -> pd.DataFrame:
    """í˜„ì¬ ë°ì´í„° êµ¬ì¡°(T, T+1, ..., T+4)ë¥¼ í™œìš©í•œ cross-horizon íŒŒìƒë³€ìˆ˜"""
    T  = COLS["demand_T"]
    T1 = COLS["demand_Tp1"]
    T2 = COLS["demand_Tp2"]
    T3 = COLS["demand_Tp3"]
    T4 = COLS["demand_Tp4"]

    # 1) Diff & Ratio (T ê¸°ì¤€ ë³€í™”)
    for k, col in enumerate([T1, T2, T3, T4], start=1):
        if col in df.columns and T in df.columns:
            df[f"lag_diff_T+{k}"] = (df[col] - df[T]).fillna(0.0)
            ratio = np.where(df[T] != 0, df[col] / df[T], np.nan)
            df[f"lag_ratio_T+{k}"] = _stabilize_ratio(pd.Series(ratio), 0.0, 5.0, 0.0)

    # 2) ì „ì²´ ë¯¸ë˜ ìˆ˜ì£¼ëŸ‰ ìš”ì•½
    future_cols = [c for c in [T1, T2, T3, T4] if c in df.columns]
    if future_cols:
        df["cumsum_lag"] = df[future_cols].sum(axis=1)
        df["mean_future"] = df[future_cols].mean(axis=1)
        df["std_future"] = df[future_cols].std(axis=1)
        df["instability_coef"] = np.where(df["mean_future"] != 0,
                                          df["std_future"] / df["mean_future"], 0)
    else:
        print("ë¯¸ë˜ ì‹œì  ì—´ì´ ë¶€ì¡±í•˜ì—¬ ìš”ì•½í˜• íŒŒìƒë³€ìˆ˜ ìƒëµ")

    # 3) ì „ì²´ ì¶”ì„¸ (Tâ†’T+4 ê¸°ì¤€)
    if T in df.columns and T4 in df.columns:
        delta = (df[T4] - df[T]).astype(float)
        df["trend_sign"] = np.sign(delta).astype("Int64")
        df["growth_index_T4"] = np.where(df[T] != 0, df[T4] / df[T], np.nan)
    elif T in df.columns and T2 in df.columns:
        delta = (df[T2] - df[T]).astype(float)
        df["trend_sign"] = np.sign(delta).astype("Int64")
        df["growth_index_T4"] = np.where(df[T] != 0, df[T2] / df[T], np.nan)
        print("T+4 ë¶€ì¬ë¡œ trend_sign/growth_index_T4ë¥¼ 2-step ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°")

    # 4) ì‘ë…„ ëŒ€ë¹„(ìˆì„ ê²½ìš°)
    if "ì‘ë…„ Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰" in df.columns:
        df["yoy_T"] = np.where(df["ì‘ë…„ Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"] != 0,
                               df[T] / df["ì‘ë…„ Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"], np.nan)

    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.fillna(0, inplace=True)
    return df


def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    """Datetime ê¸°ë°˜ ì‹œê°„ íŒŒìƒ â€” ê¸°ì¡´ DOW ë¬¸ìì—´ ì œê±° í›„ ìˆ«ìí˜• ìš”ì¼ ì¬ê³„ì‚°"""
    dt_col = COLS["dt"]
    if dt_col not in df.columns:
        print("ì‹œê°„ íŒŒìƒ ìƒëµ: DateTime ì»¬ëŸ¼ ì—†ìŒ")
        return df
    if not np.issubdtype(df[dt_col].dtype, np.datetime64):
        df[dt_col] = _safe_parse_datetime(df[dt_col])

    # ê¸°ì¡´ ë¬¸ìì—´í˜• DOW ì‚­ì œ
    if "DOW" in df.columns:
        df.drop(columns=["DOW"], inplace=True)
        print("ê¸°ì¡´ 'DOW' ì»¬ëŸ¼ ì‚­ì œ (Datetime ê¸°ì¤€ìœ¼ë¡œ ìƒˆë¡œ ê³„ì‚°)")

    # Datetimeìœ¼ë¡œë¶€í„° ì‹œê°„ ê´€ë ¨ ë³€ìˆ˜ ìƒì„±
    df["dow"] = df[dt_col].dt.weekday       # ìš”ì¼ (0=ì›”, 6=ì¼)
    df["month"] = df[dt_col].dt.month
    df["hour"] = df[dt_col].dt.hour
    df["minute"] = df[dt_col].dt.minute

    # ì‹œê°„ ì£¼ê¸°ì„± ë°˜ì˜
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
    df["minute_sin"] = np.sin(2 * np.pi * df["minute"] / 60)
    df["minute_cos"] = np.cos(2 * np.pi * df["minute"] / 60)

    return df

# =========================
# ì œí’ˆ í´ëŸ¬ìŠ¤í„°ë§ (K=4)
# =========================

def cluster_products(df: pd.DataFrame, demand_col: str, prod_col: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
    if not {demand_col, prod_col}.issubset(df.columns):
        print("í´ëŸ¬ìŠ¤í„°ë§ ìƒëµ: í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df, pd.DataFrame()

    feats = df.groupby(prod_col)[demand_col].agg(
        Mean_Demand="mean",
        Std_Demand="std",
        Zero_Ratio=lambda x: (x == 0).mean(),
        CV_Ratio=lambda x: (x.std() / x.mean()) if x.mean() != 0 else 0.0,
    ).fillna(0)
    feats.replace([np.inf, -np.inf], 0, inplace=True)

    X = StandardScaler().fit_transform(feats)
    km = KMeans(n_clusters=4, random_state=42, n_init=10)
    labels = km.fit_predict(X)

    feats["_label"] = labels
    order = feats.groupby("_label")["Mean_Demand"].mean().sort_values().index.tolist()
    relabel_map = {old: new for new, old in enumerate(order)}
    feats["Cluster"] = [relabel_map[l] for l in labels]

    df_out = df.merge(feats[["Cluster"]], left_on=prod_col, right_index=True, how="left")
    feats.rename(columns={"Cluster": "Cluster(0=í¬ì†Œ,1=ê°„í—,2=ë‹¤ìˆ˜,3=ì¤‘ìš”)"}, inplace=True)

    print("ì œí’ˆ í´ëŸ¬ìŠ¤í„° ë¶„í¬:")
    print(feats["Cluster(0=í¬ì†Œ,1=ê°„í—,2=ë‹¤ìˆ˜,3=ì¤‘ìš”)"].value_counts().sort_index().to_string())

    return df_out, feats

# =========================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# =========================

def build_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    prod_col, dt_col = COLS["prod"], COLS["dt"]

    # 1) DateTime ë³€í™˜
    if dt_col in df.columns:
        df[dt_col] = _safe_parse_datetime(df[dt_col])
        print(f"DateTime ë³€í™˜ ì™„ë£Œ | ê²°ì¸¡: {df[dt_col].isna().sum()}")
    else:
        print("DateTime ì»¬ëŸ¼ ì—†ìŒ â€” ì‹œê°„ íŒŒìƒì€ ê±´ë„ˆëœ€")

    # 2) ì™„ì „ ì¤‘ë³µ ì œê±° ë° í‚¤ ë³‘í•©
    df, _ = _drop_full_duplicates(df)
    if prod_col in df.columns and dt_col in df.columns:
        df, _ = _dedup_by_key_mean(df, prod_col, dt_col)

    # 3) Humidity ì´ìƒì¹˜ ì²˜ë¦¬ (clip ë°©ì‹)
    if "Humidity" in df.columns:
        before_outliers = (df["Humidity"] > 100).sum() + (df["Humidity"] < 0).sum()
        if before_outliers > 0:
            print(f"ğŸŒ¡ï¸ Humidity ì´ìƒì¹˜ {before_outliers}ê±´ â†’ 0~100ìœ¼ë¡œ clip ì²˜ë¦¬")
        df["Humidity"] = df["Humidity"].clip(lower=0, upper=100)

    # 4) Cross-horizon íŒŒìƒ
    df = add_cross_horizon_features(df)

    # 5) ì‹œê°„ íŒŒìƒ
    df = add_time_features(df)

    # 6) ì œí’ˆ í´ëŸ¬ìŠ¤í„°ë§
    demand_col = COLS["demand_T"] if COLS["demand_T"] in df.columns else None
    clus_summary = pd.DataFrame()
    if demand_col:
        df, clus_summary = cluster_products(df, demand_col, prod_col)

    # 7) ì •ë ¬
    sort_cols = [c for c in [prod_col, dt_col] if c in df.columns]
    if sort_cols:
        df = df.sort_values(sort_cols).reset_index(drop=True)

    return df, clus_summary

# =========================
# CLI
# =========================

def _read_csv(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path)
    except Exception:
        return pd.read_csv(path, encoding="utf-8-sig")

def main(argv: Optional[List[str]] = None) -> int:
    p = argparse.ArgumentParser(description="Preprocess & Feature Engineering")
    p.add_argument("--in", dest="inp", required=True)
    p.add_argument("--out", dest="out", required=True)
    args = p.parse_args(argv)

    df = _read_csv(args.inp)
    print(f"ì…ë ¥: {args.inp} | shape={df.shape}")

    out_df, clus_summary = build_features(df)

    out_df.to_csv(args.out, index=False, encoding="utf-8-sig")
    print(f"ì €ì¥: {args.out} | shape={out_df.shape}")

    if not clus_summary.empty:
        clus_path = args.out.replace(".csv", "_cluster_summary.csv")
        clus_summary.to_csv(clus_path, encoding="utf-8-sig")
        print(f"í´ëŸ¬ìŠ¤í„° ìš”ì•½ ì €ì¥: {clus_path}")
    return 0

if __name__ == "__main__":
    sys.exit(main())